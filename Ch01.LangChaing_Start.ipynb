{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4ad5951",
   "metadata": {},
   "source": [
    "---\n",
    "layout: post\n",
    "title:  \"Ch01.LangChain시작하기\"\n",
    "date:   2025-06-26 01:00:00 +0700\n",
    "categories: [LLM]\n",
    "---\n",
    "\n",
    "<script type=\"text/x-mathjax-config\">\n",
    "MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]}});\n",
    "</script>\n",
    "<script type=\"text/javascript\" src=\"https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML\">\n",
    "</script>\n",
    "\n",
    "### 참조 사이트.\n",
    "해당 Post는 <a href=\"https://wikidocs.net/book/14314\">LangChain 위키독스</a>에 나와있는 예제와 흐름을 파악하는 용도 입니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ce5a82",
   "metadata": {},
   "source": [
    "### LangChain Expression Language(LECL)\n",
    "\n",
    "기본 적인 Prompt + 모델 + 출력 파서에 대해 알아본다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a182e24a",
   "metadata": {},
   "source": [
    "#### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01cf379f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444b34a9",
   "metadata": {},
   "source": [
    "#### Prompt 설정 방법\n",
    "\n",
    "기본적으로 많이 사용하는 <code>PromptTemplate</code>는 아래와 같은 Argument로서 사용된다.\n",
    "\n",
    "```python\n",
    "PromptTemplate(\n",
    "    input_variables: List[str],\n",
    "    template: str,\n",
    "    partial_variables: Optional[Dict[str, Any]] = None,\n",
    "    validate_template: bool = True,\n",
    "    template_format: str = \"f-string\"\n",
    ")\n",
    "```\n",
    "\n",
    "- input_variables: 탬플릿에서 사용할 변수명들의 리스트\n",
    "- template: Prompt 본문 문자열 (e.g., Hello {name})\n",
    "- partial_variables: 일부 변수에 미리 값을 지정\n",
    "- validate_template: 변수와 탬플릿이 일치하는지 검사\n",
    "- template_format: f-string과 같은 Format 형식\n",
    "\n",
    "실제 사용예시는 아래와 같다.\n",
    "\n",
    "**기본 사용 방법**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10858061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is a good name for a company that makes toys?\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"], # 사용할 변수 명\n",
    "    template=\"What is a good name for a company that makes {product}?\" # 실제 Model에 넘길 Prompt\n",
    ")\n",
    "\n",
    "print(prompt.format(product=\"toys\")) # 변수에 값을 넣어서 사용\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9396ba60",
   "metadata": {},
   "source": [
    "**partial_variables 예시**  \n",
    "\n",
    "아래와 같이 partial_variables는 사전에 정의할 default variable이고, 추후 다른 값으로 변환 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "061d7b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quick fox is running fast.\n",
      "The slow fox is running fast.\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"adjective\", \"noun\"],\n",
    "    template=\"The {adjective} {noun} is running fast.\",\n",
    "    partial_variables={\"adjective\": \"quick\"}\n",
    ")\n",
    "\n",
    "print(prompt.format(noun=\"fox\"))\n",
    "print(prompt.format(noun=\"fox\", adjective=\"slow\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013aa330",
   "metadata": {},
   "source": [
    "#### Model Define\n",
    "\n",
    "Local에서 Qwen3-4b model을 올려두고 사용한다. 아래와 같이 Local에서 띄운 vllm을 호출하여 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2741762e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(\n",
    "    base_url=\"http://localhost:8000/v1\",\n",
    "    api_key=\"EMPTY\",\n",
    "    model=\"Qwen/Qwen3-4B\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb2e538",
   "metadata": {},
   "source": [
    "#### StrOutputParser\n",
    "\n",
    "LLM Model의 Output을 받아서 사용하기 위하여 사용된다. 주로 chain으로 연결된 LECL에서 많이 사용되며, 주로 사용되는 기능은 아래와 같다.\n",
    "\n",
    "- <code>.invoke(output)</code>: 문자열 출력 결과를 반환 (일반적으로 내부적으로 사용됨)\n",
    "- <code>.parse(text)</code>: 텍스트를 받아 가공 없이 문자열로 리턴\n",
    "- <code>.parse_result(result)</code>: LLMResult 객체에서 첫 번째 텍스트 응답을 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4eab98",
   "metadata": {},
   "source": [
    "#### LECL Example\n",
    "\n",
    "실제 Prompt를 적용하고 LECL을 구성하여 Output을 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adac7c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template 선언\n",
    "template = \"\"\"\n",
    "당신은 영어를 가르치는 10년차 영어 선생님입니다. 상황에 [FORMAT]에 영어 회화를 작성해 주세요.\n",
    "\n",
    "상황:\n",
    "{question}\n",
    "\n",
    "FORMAT:\n",
    "- 영어 회화:\n",
    "- 한글 해석:\n",
    "\"\"\"\n",
    "\n",
    "# Prompt 생성\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Local Server Vllm 선언\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"http://localhost:8000/v1\",\n",
    "    api_key=\"EMPTY\",\n",
    "    model=\"Qwen/Qwen3-4B\"\n",
    ")\n",
    "\n",
    "# 문자열 파서 선언\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# LECL 선언\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aed7032",
   "metadata": {},
   "source": [
    ".invoke는 Model에 Prompt를 입력으로 넣어서 출력을 얻어내는 과정이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d32bd2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user wants me to create an English conversation for a restaurant order scenario, with both English and Korean interpretations. Let me start by thinking about the typical interactions in a restaurant. The customer would start by greeting the server, then ask for the menu. The server would respond and maybe offer recommendations. The customer would then place an order, maybe ask about the menu items, and the server would confirm the order. Also, the customer might ask about the bill or special requests like drinks.\n",
      "\n",
      "I need to make sure the conversation is natural and realistic. Let me list out the possible steps: greeting, ordering, asking about dishes, special requests, confirming the order, and ending with a thank you. Each part should have a simple, clear exchange. I should use common phrases that a customer would use in a restaurant. Also, the Korean translations need to be accurate, so I have to make sure the vocabulary matches the English words. For example, \"What's on the menu today?\" translates to \"오늘 메뉴는 뭐예요?\" \n",
      "\n",
      "Wait, maybe I should include some specific dishes to make it more concrete. Like ordering a burger, fries, and a drink. The server might mention if the burger is spicy or not. Also, the customer might ask about the price or if there's a discount. But since the user didn't specify, maybe keep it simple. Also, the conversation should be in a friendly and polite tone. Let me check the flow again. Start with greeting, then order, then ask about the items, confirm the order, and end with thanks. That should cover the main points. Now, I need to write each line in English, then the Korean translation. Make sure the Korean is correct and natural. Let me draft that.\n",
      "</think>\n",
      "\n",
      "- 영어 회화:  \n",
      "**Customer:** Hello, can I see the menu, please?  \n",
      "**Server:** Of course! Here you go.  \n",
      "**Customer:** Do you have any recommendations today?  \n",
      "**Server:** Sure! Our grilled chicken burger is very popular. Would you like to try it?  \n",
      "**Customer:** Yes, I’d like one. Also, can I have some fries and a soda?  \n",
      "**Server:** Certainly! Anything else?  \n",
      "**Customer:** Maybe a side of salad?  \n",
      "**Server:** Great! Your order is: one grilled chicken burger, fries, a soda, and a salad.  \n",
      "**Customer:** Thank you! How long will it take?  \n",
      "**Server:** About 15 minutes. Would you like to wait here or sit at the table?  \n",
      "**Customer:** I’ll wait here.  \n",
      "**Server:** Alright, your food will be ready shortly.  \n",
      "\n",
      "- 한글 해석:  \n",
      "**고객:** 안녕하세요, 메뉴를 보여줄 수 있을까요?  \n",
      "**서버:** 물론이죠! 여기 있습니다.  \n",
      "**고객:** 오늘 추천 메뉴는 뭐예요?  \n",
      "**서버:** 네, 우리 그릴 치킨 버거가 인기 많아요. 시도해볼까요?  \n",
      "**고객:** 네, 하나 주세요. 그리고 감자 길이와 코ke를 하나 더 주세요.  \n",
      "**서버:** 물론이죠! 더 주문할까요?  \n",
      "**고객:** 아마 채소 샐러드도 하나 더요.  \n",
      "**서버:** 좋습니다! 주문 내역은: 그릴 치킨 버거 하나, 감자 길이, 코ke, 채소 샐러드입니다.  \n",
      "**고객:** 감사합니다! 얼마나 지나는 거예요?  \n",
      "**서버:** 약 15분 정도입니다. 여기 앉아서 기다릴까요요?  \n",
      "**고객:** 여기 앉아서 기다릴게요.  \n",
      "**서버:** 좋아요, 곧 음식이 준비될 거예요.\n"
     ]
    }
   ],
   "source": [
    "result = chain.invoke({\"question\": \"레스토랑에서 주문하는 상황\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb49e75",
   "metadata": {},
   "source": [
    ".stream은 Model의 Output을 실시간으로 받아내는 과정이다. 아래 코드를 보면 아래와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49928656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user wants me to create an English conversation for ordering pizza in the US, with both English and Korean translations. Let me start by thinking about the typical steps in a pizza order. First, the customer would greet the cashier, maybe say hello. Then they'd ask for the menu or what's available. Next, they'd order the pizza, specifying the size, toppings, and any extra things like cheese or sauce. They might also ask about delivery or pickup. Then the cashier would confirm the order, and the customer thanks them.\n",
      "\n",
      "I need to make sure the conversation is realistic and covers common scenarios. Let me check if there are any specific terms or phrases that are commonly used in US pizza places. For example, \"large pizza,\" \"pepperoni,\" \"extra cheese,\" \"hold the pepperoni,\" \"delivery,\" \"pickup,\" \"total cost,\" \"thank you.\"\n",
      "\n",
      "Also, the Korean translation should be accurate. I need to make sure the translations are natural and not literal. For instance, \"Would you like to order something?\" in Korean would be \"어떤 것을 주문하시겠어요?\" and so on.\n",
      "\n",
      "Wait, should I include a part where the customer asks about the toppings? Maybe the cashier lists some options. Also, maybe the customer asks for a specific size. Let me structure the conversation step by step. Start with greeting, then order details, then payment or delivery, and end with thanks.\n",
      "\n",
      "Let me draft the English part first. The customer says hello, asks what's available. The cashier responds with menu options. Customer orders a large pizza with pepperoni and extra cheese. Then asks if they can have it delivered. Cashier says yes and gives the total. Customer thanks and leaves.\n",
      "\n",
      "Now the Korean translation. Make sure the terms match. For example, \"large pizza\" is \"큰 피자,\" \"pepperoni\" is \"피퍼로니,\" \"extra cheese\" is \"추가 치즈.\" Also, \"delivery\" is \"배달,\" \"pickup\" is \"픽업,\" \"total cost\" is \"총 금액.\"\n",
      "\n",
      "I need to check for any possible errors. Maybe the cashier says \"Yes, we can deliver it.\" In Korean, that would be \"네, 배달해드릴 수 있어요.\" Also, the customer says \"Thank you,\" which is \"감사합니다.\"\n",
      "\n",
      "I think that's covered. Let me put it all together now.\n",
      "</think>\n",
      "\n",
      "- 영어 회화:  \n",
      "**Customer:** Hi, can I order something?  \n",
      "**Cashier:** Sure! What would you like to order?  \n",
      "**Customer:** I’d like a large pizza with pepperoni and extra cheese.  \n",
      "**Cashier:** Great! Would you like it delivered or picked up?  \n",
      "**Customer:** Delivery, please.  \n",
      "**Cashier:** Of course! The total will be $15.99.  \n",
      "**Customer:** Thank you!  \n",
      "**Cashier:** You’re welcome! Have a great day!  \n",
      "\n",
      "- 한글 해석:  \n",
      "**고객:** 안녕하세요, 주문할 수 있나요?  \n",
      "**카시어:** 물론이죠! 어떤 것을 주문하시겠어요?  \n",
      "**고객:** 피퍼로니와 추가 치즈를 넣은 큰 피자를 주문하고 싶어요.  \n",
      "**카시어:** 좋아요! 배달이나 픽업 중 하나를 선택해 주세요.  \n",
      "**고객:** 배달을 해주실 수 있나요?  \n",
      "**카시어:** 물론이죠! 총 금액은 15.99 달러입니다.  \n",
      "**고객:** 감사합니다.  \n",
      "**카시어:** 네, 감사합니다! 좋은 하루 보내세요!"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessageChunk\n",
    "\n",
    "'''\n",
    "Model의 Output을 실시간으로 받아낸다. \n",
    "Generator로서 생성되며\n",
    "각각의 값은 2가지가 될 수 있다.\n",
    "    - AIMessageChunk: 여러 Token 묶음\n",
    "    - token: 1개의 token\n",
    "'''\n",
    "response = chain.stream({\"question\": \"미국에서 피자 주문\"}) \n",
    "\n",
    "answer = \"\"\n",
    "for token in response: # generator안의 값을 계속해서 받아온다.\n",
    "    if isinstance(token, AIMessageChunk): # 여러 token이 들어오는 경우 for문을 돌며 각각의 token의 text를 확인한다.\n",
    "        answer += token.content\n",
    "        print(token.content, end=\"\", flush=True)\n",
    "    elif isinstance(token, str): # 1개의 token인 경우 바로 확인.\n",
    "        answer += token\n",
    "        print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9692fd1c",
   "metadata": {},
   "source": [
    "**Appendix: think token**: 해당 토큰은 현재 사용하는 vllm model (qwen3)의 특징이다. COT과정과 답변을 함께 출력하게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c789c82",
   "metadata": {},
   "source": [
    "<hr>\n",
    "참조: <a href=\"https://wikidocs.net/book/14314\">LangChain 위키독스</a><br>\n",
    "참조: <a href=\"https://github.com/wjddyd66/LLM/tree/main\">원본 코드</a><br>\n",
    "\n",
    "코드에 문제가 있거나 궁금한 점이 있으면 wjddyd66@naver.com으로  Mail을 남겨주세요."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
